{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64316b58",
   "metadata": {},
   "source": [
    "# 中国地面气候资料日值数据集(V3.0).txt转成矢量数据.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88192ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T15:50:31.312463Z",
     "start_time": "2021-10-25T15:50:31.298467Z"
    }
   },
   "outputs": [],
   "source": [
    "#数据类型：气象站点数据.txt(中国地面气候资料日值数据集(V3.0))\n",
    "#实验目的：1.气象站点TXT文件批量转shp\n",
    "#          1.1将气象站点TXT数据批量转成csv格式\n",
    "#          1.2提取气象站点TXT数据逐日数据批量转成csv格式\n",
    "#          1.3将csv站点数据批量转成shp数据\n",
    "#          1.4shp数据批量投影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b3a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T15:50:31.849441Z",
     "start_time": "2021-10-25T15:50:31.314463Z"
    }
   },
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "#导入os和pandas库\n",
    "import os\n",
    "import pandas as pd\n",
    "import shapefile as shp\n",
    "import csv\n",
    "import codecs\n",
    "import os\n",
    "from osgeo import osr\n",
    "from rich.progress import track\n",
    "\n",
    "#设置输入输出路径\n",
    "input_dir=(r'K:\\全国气象数据（2000-2018年）\\2021年\\0_data')#存放TXT文件路径\n",
    "output_csvdir=(r'K:\\全国气象数据（2000-2018年）\\2021年\\5_逐日数据处理\\ss')#存放csv文件路径\n",
    "output_shpdir=(r'K:\\全国气象数据（2000-2018年）\\2021年\\5_逐日数据处理\\sss')#存放shp文件路径\n",
    "\n",
    "#修改当前工作路径\n",
    "os.chdir(input_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b3012d",
   "metadata": {},
   "source": [
    "## 剔除txt中异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112e99cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T15:50:39.779640Z",
     "start_time": "2021-10-25T15:50:31.851413Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取路径下所有文件\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    print(files[1])\n",
    "# 存放路径下数据和文件名\n",
    "dataTEM = []\n",
    "dataGST = []\n",
    "dataSSD = []\n",
    "dataRHU = []\n",
    "dataPRE = []\n",
    "filenameTEM = []\n",
    "filenameGST = []\n",
    "filenameSSD = []\n",
    "filenameRHU = []\n",
    "filenamePRE = []\n",
    "# 将不同类型的数据单独存放\n",
    "for i in range(len(files)):\n",
    "    io = files[i]\n",
    "    if os.path.splitext(files[i])[1] == '.txt':\n",
    "        if files[i].split('-')[1] == 'TEM':\n",
    "            dataTEM.append(pd.read_table(io, sep='\\s+', header=None))\n",
    "            filenameTEM.append(files[i].split('.')[0])\n",
    "            # print(filenameTEM[0])\n",
    "        if files[i].split('-')[1] == 'GST':\n",
    "            dataGST.append(pd.read_table(io, sep='\\s+', header=None))\n",
    "            filenameGST.append(files[i].split('.')[0])\n",
    "            # print(filenameTEM[0])\n",
    "        if files[i].split('-')[1] == 'RHU':\n",
    "            dataRHU.append(pd.read_table(io, sep='\\s+', header=None))\n",
    "            filenameRHU.append(files[i].split('.')[0])\n",
    "            # print(filenameTEM[0])\n",
    "        if files[i].split('-')[1] == 'PRE':\n",
    "            dataPRE.append(pd.read_table(io, sep='\\s+', header=None))\n",
    "            filenamePRE.append(files[i].split('.')[0])\n",
    "            # print(filenameTEM[0])\n",
    "        if files[i].split('-')[1] == 'SSD':\n",
    "            dataSSD.append(pd.read_table(io, sep='\\s+', header=None))\n",
    "            filenameSSD.append(files[i].split('.')[0])\n",
    "            # print(filenameTEM[0])\n",
    "\n",
    "# 剔除异常值：1.其中整月全部日数据都为异常值，则删除该站点；2.个别异常值则用相邻日数据替代\n",
    "# 注：原始站点数据个别站点缺失某些日数据，未处理；\n",
    "# 剔除整月全部为异常值的站点\n",
    "def DelectErrorstation(dataset):\n",
    "    for i in range(len(dataset)):\n",
    "        a = dataset[i].groupby([0], as_index=False)[7].mean()  # 求每个站点月平均值，提取整月都为异常值的站点\n",
    "        b = a[(a[7] == 32766) | (a[7] == 999990)][0]  # 提取整月都为异常值的站点\n",
    "        b.index.name = None  # 去行名称\n",
    "        dataset[i] = dataset[i][~dataset[i][0].isin(b)]  # 删除包含异常站点的数据\n",
    "        if dataset[i].shape[1] == 13:\n",
    "            a = dataset[i].groupby([0], as_index=False)[8].mean()  # 求每个站点月平均值，提取整月都为异常值的站点\n",
    "            b = a[(a[8] == 32766) | (a[8] == 999990)][0]  # 提取整月都为异常值的站点\n",
    "            b.index.name = None  # 去行名称\n",
    "            dataset[i] = dataset[i][~dataset[i][0].isin(b)]  # 删除包含异常站点的数据\n",
    "            a = dataset[i].groupby([0], as_index=False)[9].mean()  # 求每个站点月平均值，提取整月都为异常值的站点\n",
    "            b = a[(a[9] == 32766) | (a[9] == 999990)][0]  # 提取整月都为异常值的站点\n",
    "            b.index.name = None  # 去行名称\n",
    "            dataset[i] = dataset[i][~dataset[i][0].isin(b)]  # 删除包含异常站点的数据\n",
    "\n",
    "DelectErrorstation(dataTEM)\n",
    "DelectErrorstation(dataGST)\n",
    "DelectErrorstation(dataRHU)\n",
    "DelectErrorstation(dataPRE)\n",
    "DelectErrorstation(dataSSD)\n",
    "\n",
    "# 个别异常值则用相邻日数据替代\n",
    "def ReplaceErrorvalue(data_month):\n",
    "    print('异常值去除')\n",
    "    for i in range(len(data_month)):\n",
    "        #     nodata = dataTEM[i][(dataTEM[i][7] > 30000)|(dataTEM[i][8] > 30000)|(dataTEM[i][9] > 30000)]\n",
    "        nodata1 = data_month[i][(data_month[i][7] > 30000)].index\n",
    "        for j in range(len(nodata1)):\n",
    "            if data_month[i].loc[nodata1[j],6] > 1:\n",
    "                data_month[i].loc[nodata1[j],7] = data_month[i].loc[nodata1[j]-1,7]\n",
    "            elif (data_month[i].loc[nodata1[j],6] <= 1) & (data_month[i].loc[nodata1[j]+1,7] > 30000):\n",
    "                datastation = data_month[i][data_month[i][0] == data_month[i].loc[nodata1[j],0]]\n",
    "                datamean = datastation[datastation[7] < 30000][7].mean()\n",
    "                data_month[i].loc[nodata1[j],7] = datamean\n",
    "            else:\n",
    "                data_month[i].loc[nodata1[j],7] = data_month[i].loc[nodata1[j]+1,7]\n",
    "        if data_month[i].shape[1] == 13:\n",
    "            nodata2 = data_month[i][(data_month[i][8] > 30000)].index\n",
    "#             print(nodata2)\n",
    "            nodata3 = data_month[i][(data_month[i][9] > 30000)].index\n",
    "#             print(nodata3)\n",
    "            for j in range(len(nodata2)):\n",
    "                if data_month[i].loc[nodata2[j],6] > 1:\n",
    "                    data_month[i].loc[nodata2[j],8] = data_month[i].loc[nodata2[j]-1,8]\n",
    "                elif (data_month[i].loc[nodata2[j],6] <= 1) & (data_month[i].loc[nodata2[j]+1,8] > 30000):\n",
    "                    datastation = data_month[i][data_month[i][0] == data_month[i].loc[nodata2[j],0]]\n",
    "                    datamean = datastation[datastation[8] < 30000][8].mean()\n",
    "                    data_month[i].loc[nodata2[j], 8] = datamean\n",
    "                else:\n",
    "                    data_month[i].loc[nodata2[j],8] = data_month[i].loc[nodata2[j]+1,8]\n",
    "            for j in range(len(nodata3)):\n",
    "                if data_month[i].loc[nodata3[j],6] > 1:\n",
    "                    data_month[i].loc[nodata3[j],9] = data_month[i].loc[nodata3[j]-1,9]\n",
    "                elif (data_month[i].loc[nodata3[j],6] <= 1) & (data_month[i].loc[nodata3[j]+1,9] > 30000):\n",
    "                    datastation = data_month[i][data_month[i][0] == data_month[i].loc[nodata3[j],0]]\n",
    "                    datamean = datastation[datastation[9] < 30000][9].mean()\n",
    "                    data_month[i].loc[nodata3[j],9] = datamean\n",
    "                else:\n",
    "                    data_month[i].loc[nodata3[j],9] = data_month[i].loc[nodata3[j]+1,9]\n",
    "#检测是否有异常值，验证数据\n",
    "    for i in range(len(data_month)):\n",
    "        #     nodata = dataTEM[i][(dataTEM[i][7] > 30000)|(dataTEM[i][8] > 30000)|(dataTEM[i][9] > 30000)]\n",
    "        nodata1 = data_month[i][(data_month[i][7] > 30000)].index\n",
    "        if data_month[i].shape[1] == 13:\n",
    "            nodata2 = data_month[i][(data_month[i][8] > 30000)].index\n",
    "            nodata3 = data_month[i][(data_month[i][9] > 30000)].index\n",
    "        else:\n",
    "            nodata2 = pd.DataFrame([])\n",
    "            nodata3 = pd.DataFrame([])\n",
    "        if nodata1.empty & nodata2.empty & nodata3.empty:\n",
    "            print('无异常值')\n",
    "        else:\n",
    "            print('有异常值')\n",
    "\n",
    "ReplaceErrorvalue(dataTEM)\n",
    "ReplaceErrorvalue(dataGST)\n",
    "ReplaceErrorvalue(dataSSD)\n",
    "ReplaceErrorvalue(dataRHU)\n",
    "ReplaceErrorvalue(dataPRE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f9171",
   "metadata": {},
   "source": [
    "## 将txt格式转换成csv格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e32dea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T15:50:44.299617Z",
     "start_time": "2021-10-25T15:50:39.780639Z"
    }
   },
   "outputs": [],
   "source": [
    "#保存数据到csv\n",
    "#提取数据列\n",
    "#TEM\n",
    "for i in track(range(len(dataTEM))):\n",
    "    tem = dataTEM[i][7] *0.1\n",
    "    htem = dataTEM[i][8] *0.1\n",
    "    ltem = dataTEM[i][9] *0.1\n",
    "    #提取站点\n",
    "    station = dataTEM[i][0]    \n",
    "    #提取站点经纬度\n",
    "    locationINT = dataTEM[i].iloc[:,1:3] // 100\n",
    "    locationPOINT = dataTEM[i].iloc[:,1:3] % 100 / 60\n",
    "    locationactual = locationINT + locationPOINT\n",
    "    locationactual.columns = ['Y','X']\n",
    "    X = locationactual.loc[:,'X']\n",
    "    Y = locationactual.loc[:,'Y']\n",
    "    #提取站点海拔高度\n",
    "    height = dataTEM[i][3] / 10\n",
    "    #提取日期\n",
    "    year = dataTEM[i][4]\n",
    "    month = dataTEM[i][5]\n",
    "    day = dataTEM[i][6]\n",
    "    #写出数据\n",
    "    final_data = pd.DataFrame({'X':X,'Y':Y,'站点':station,'海拔高度':height,'年':year,'月':month,'日':day,'日均气温':tem,'月均最高气温':htem,'月均最低气温':ltem})\n",
    "    final_data.to_csv(output_csvdir+ os.sep +filenameTEM[i]+'_day.csv',encoding=\"utf_8_sig\")\n",
    "#     final_data.to_excel(output_csvdir+ os.sep +filenameTEM[i]+'_day.xlsx',encoding=\"utf_8_sig\")\n",
    "#GST\n",
    "for i in track(range(len(dataGST))):\n",
    "    tem = dataGST[i][7] *0.1\n",
    "    htem = dataGST[i][8] *0.1\n",
    "    ltem = dataGST[i][9] *0.1\n",
    "    #提取站点\n",
    "    station = dataGST[i][0]    \n",
    "    #提取站点经纬度\n",
    "    locationINT = dataGST[i].iloc[:,1:3] // 100\n",
    "    locationPOINT = dataGST[i].iloc[:,1:3] % 100 / 60\n",
    "    locationactual = locationINT + locationPOINT\n",
    "    locationactual.columns = ['Y','X']\n",
    "    X = locationactual.loc[:,'X']\n",
    "    Y = locationactual.loc[:,'Y']\n",
    "    #提取站点海拔高度\n",
    "    height = dataGST[i][3] / 10\n",
    "    #提取日期\n",
    "    year = dataGST[i][4]\n",
    "    month = dataGST[i][5]\n",
    "    day = dataGST[i][6]\n",
    "    #写出数据\n",
    "    final_data = pd.DataFrame({'X':X,'Y':Y,'站点':station,'海拔高度':height,'年':year,'月':month,'日':day,'日均气温':tem,'月均最高气温':htem,'月均最低气温':ltem})\n",
    "    final_data.to_csv(output_csvdir+ os.sep +filenameGST[i]+'_day.csv',encoding=\"utf_8_sig\")\n",
    "#     final_data.to_excel(output_csvdir+ os.sep +filenameGST[i]+'_day.xlsx',encoding=\"utf_8_sig\")\n",
    "#RHU\n",
    "for i in track(range(len(dataRHU))):\n",
    "    rhu = dataRHU[i][7]\n",
    "    #提取站点\n",
    "    station = dataRHU[i][0]    \n",
    "    #提取站点经纬度\n",
    "    locationINT = dataRHU[i].iloc[:,1:3] // 100\n",
    "    locationPOINT = dataRHU[i].iloc[:,1:3] % 100 / 60\n",
    "    locationactual = locationINT + locationPOINT\n",
    "    locationactual.columns = ['Y','X']\n",
    "    X = locationactual.loc[:,'X']\n",
    "    Y = locationactual.loc[:,'Y']\n",
    "    #提取站点海拔高度\n",
    "    height = dataRHU[i][3] / 10\n",
    "    #提取日期\n",
    "    year = dataRHU[i][4]\n",
    "    month = dataRHU[i][5]\n",
    "    day = dataRHU[i][6]\n",
    "    #写出数据\n",
    "    final_data = pd.DataFrame({'X':X,'Y':Y,'站点':station,'海拔高度':height,'年':year,'月':month,'日':day,'相对湿度':rhu})\n",
    "    final_data.to_csv(output_csvdir+ os.sep +filenameRHU[i]+'_day.csv',encoding=\"utf_8_sig\")\n",
    "#     final_data.to_excel(output_csvdir+ os.sep +filenameRHU[i]+'_day.xlsx',encoding=\"utf_8_sig\")\n",
    "#PRE\n",
    "for i in track(range(len(dataPRE))):\n",
    "    dpre = dataPRE[i][7] *0.1\n",
    "    npre = dataPRE[i][8] *0.1\n",
    "    pre = dataPRE[i][9] *0.1\n",
    "    #提取站点\n",
    "    station = dataPRE[i][0]    \n",
    "    #提取站点经纬度\n",
    "    locationINT = dataPRE[i].iloc[:,1:3] // 100\n",
    "    locationPOINT = dataPRE[i].iloc[:,1:3] % 100 / 60\n",
    "    locationactual = locationINT + locationPOINT\n",
    "    locationactual.columns = ['Y','X']\n",
    "    X = locationactual.loc[:,'X']\n",
    "    Y = locationactual.loc[:,'Y']\n",
    "    #提取站点海拔高度\n",
    "    height = dataPRE[i][3] / 10\n",
    "    #提取日期\n",
    "    year = dataPRE[i][4]\n",
    "    month = dataPRE[i][5]\n",
    "    day = dataPRE[i][6]\n",
    "    #写出数据\n",
    "    final_data = pd.DataFrame({'X':X,'Y':Y,'站点':station,'海拔高度':height,'年':year,'月':month,'日':day,'月白天均降水':dpre,'月夜间均降水':npre,'月均降水':pre})\n",
    "    final_data.to_csv(output_csvdir+ os.sep +filenamePRE[i]+'_day.csv',encoding=\"utf_8_sig\")\n",
    "#     final_data.to_excel(output_csvdir+ os.sep +filenamePRE[i]+'_day.xlsx',encoding=\"utf_8_sig\")\n",
    "#SSD\n",
    "for i in track(range(len(dataSSD))):\n",
    "    ssd = dataSSD[i][7]*0.1\n",
    "    #提取站点\n",
    "    station = dataSSD[i][0]    \n",
    "    #提取站点经纬度\n",
    "    locationINT = dataSSD[i].iloc[:,1:3] // 100\n",
    "    locationPOINT = dataSSD[i].iloc[:,1:3] % 100 / 60\n",
    "    locationactual = locationINT + locationPOINT\n",
    "    locationactual.columns = ['Y','X']\n",
    "    X = locationactual.loc[:,'X']\n",
    "    Y = locationactual.loc[:,'Y']\n",
    "    #提取站点海拔高度\n",
    "    height = dataSSD[i][3] / 10\n",
    "    #提取日期\n",
    "    year = dataSSD[i][4]\n",
    "    month = dataSSD[i][5]\n",
    "    day = dataSSD[i][6]\n",
    "    #写出数据\n",
    "    final_data = pd.DataFrame({'X':X,'Y':Y,'站点':station,'海拔高度':height,'年':year,'月':month,'日':day,'月均日照时数':ssd})\n",
    "    final_data.to_csv(output_csvdir+ os.sep +filenameSSD[i]+'_day.csv',encoding=\"utf_8_sig\")\n",
    "#     final_data.to_excel(output_csvdir+ os.sep +filenameSSD[i]+'_day.xlsx',encoding=\"utf_8_sig\")\n",
    "print('数据导出到excel已完成！')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bdc6f5",
   "metadata": {},
   "source": [
    "## 根据经纬度转换csv格式为shp格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785bb33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T15:51:22.801338Z",
     "start_time": "2021-10-25T15:50:44.301122Z"
    }
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(output_csvdir):\n",
    "#     print(root) #当前目录路径\n",
    "#     print(dirs) #当前路径下所有子目录\n",
    "#     print(files) #当前路径下所有非目录子文件\n",
    "    print('开始转换矢量')\n",
    "for i in track(range(len(files))):\n",
    "    if files[i].split('.')[1] == 'csv':\n",
    "        if files[i].split('-')[1]=='GST':\n",
    "            fnn = files[i].split('.')[0]\n",
    "#             print(fnn)\n",
    "            output_shp = shp.Writer(output_shpdir+ os.sep + \"%s.shp\" % fnn, shp.POINT, encoding='gbk') #encoding='utf-8'\n",
    "            # output_shp = shp.Writer(output+ os.sep + \"%s.shp\" % fnn.split('.')[0], shp.POINT) #encoding='utf-8'\n",
    "            # for every record there must be a corresponding geometry.\n",
    "            output_shp.autoBalance = 1\n",
    "            # create the field names and data type for each.you can omit fields here\n",
    "            output_shp.field('station', 'F', 10, 8) # float\n",
    "            output_shp.field('longitude', 'F', 10, 8) # float\n",
    "            output_shp.field('latitude', 'F', 10, 8) # float\n",
    "            output_shp.field('height', 'F', 10, 8) # float\n",
    "            output_shp.field('Year', 'F', 10, 8) # int\n",
    "            output_shp.field('Mon', 'F', 10, 8) # int\n",
    "            output_shp.field('Day', 'F', 10, 8) # int            \n",
    "            output_shp.field('gst', 'F', 10, 8) # string, max-length\n",
    "            output_shp.field('hgst', 'F', 10, 8) # string, max-length\n",
    "            output_shp.field('lgst', 'F', 10, 8) # string, max-length\n",
    "            # access the CSV file\n",
    "            with codecs.open(output_csvdir+ os.sep + fnn + '.csv', 'rb', 'utf-8') as csvfile:\n",
    "                reader = csv.reader(csvfile, delimiter=',')\n",
    "            # skip the header\n",
    "                next(reader, None)\n",
    "                #loop through each of the rows and assign the attributes to variables\n",
    "                for row in reader:\n",
    "                    station = row[3]\n",
    "                    height= row[4]\n",
    "                    year = row[5]\n",
    "                    month = row[6]\n",
    "                    day = row[7]\n",
    "                    gst= row[8]\n",
    "                    hgst= row[9]\n",
    "                    lgst= row[10]\n",
    "                    lng = float(row[1])\n",
    "                    lat = float(row[2])\n",
    "                    # create the point geometry\n",
    "                    output_shp.point(lng, lat)\n",
    "                    # add attribute data\n",
    "                    output_shp.record(station,lng, lat, height,year,month,day,gst,hgst,lgst)\n",
    "        \n",
    "        if files[i].split('-')[1]=='TEM':\n",
    "            fnn = files[i].split('.')[0]\n",
    "#             print(fnn)\n",
    "            output_shp = shp.Writer(output_shpdir+ os.sep + \"%s.shp\" % fnn, shp.POINT, encoding='gbk') #encoding='utf-8'\n",
    "            # output_shp = shp.Writer(output+ os.sep + \"%s.shp\" % fnn.split('.')[0], shp.POINT) #encoding='utf-8'\n",
    "            # for every record there must be a corresponding geometry.\n",
    "            output_shp.autoBalance = 1\n",
    "            # create the field names and data type for each.you can omit fields here\n",
    "            output_shp.field('station', 'F', 10, 8) # float\n",
    "            output_shp.field('longitude', 'F', 10, 8) # float\n",
    "            output_shp.field('latitude', 'F', 10, 8) # float\n",
    "            output_shp.field('height', 'F', 10, 8) # float\n",
    "            output_shp.field('Year', 'F', 10, 8) # int\n",
    "            output_shp.field('Mon', 'F', 10, 8) # int\n",
    "            output_shp.field('Day', 'F', 10, 8) # int            \n",
    "            output_shp.field('tem', 'F', 10, 8) # string, max-length\n",
    "            output_shp.field('htem', 'F', 10, 8) # string, max-length\n",
    "            output_shp.field('ltem', 'F', 10, 8) # string, max-length\n",
    "            # access the CSV file\n",
    "            with codecs.open(output_csvdir+ os.sep + fnn + '.csv', 'rb', 'utf-8') as csvfile:\n",
    "                reader = csv.reader(csvfile, delimiter=',')\n",
    "            # skip the header\n",
    "                next(reader, None)\n",
    "                #loop through each of the rows and assign the attributes to variables\n",
    "                for row in reader:\n",
    "                    station = row[3]\n",
    "                    height= row[4]\n",
    "                    year = row[5]\n",
    "                    month = row[6]\n",
    "                    day = row[7]\n",
    "                    tem= row[8]\n",
    "                    htem= row[9]\n",
    "                    ltem= row[10]\n",
    "                    lng = float(row[1])\n",
    "                    lat = float(row[2])\n",
    "                    # create the point geometry\n",
    "                    output_shp.point(lng, lat)\n",
    "                    # add attribute data\n",
    "                    output_shp.record(station,lng, lat, height,year,month,day,tem,htem,ltem)  \n",
    "        \n",
    "        if files[i].split('-')[1]=='RHU':\n",
    "            fnn = files[i].split('.')[0]\n",
    "#             print(fnn)\n",
    "            output_shp = shp.Writer(output_shpdir+ os.sep + \"%s.shp\" % fnn, shp.POINT, encoding='gbk') #encoding='utf-8'\n",
    "            # output_shp = shp.Writer(output+ os.sep + \"%s.shp\" % fnn.split('.')[0], shp.POINT) #encoding='utf-8'\n",
    "            # for every record there must be a corresponding geometry.\n",
    "            output_shp.autoBalance = 1\n",
    "            # create the field names and data type for each.you can omit fields here\n",
    "            output_shp.field('station', 'F', 10, 8) # float\n",
    "            output_shp.field('longitude', 'F', 10, 8) # float\n",
    "            output_shp.field('latitude', 'F', 10, 8) # float\n",
    "            output_shp.field('height', 'F', 10, 8) # float\n",
    "            output_shp.field('Year', 'F', 10, 8) # int\n",
    "            output_shp.field('Mon', 'F', 10, 8) # int\n",
    "            output_shp.field('Day', 'F', 10, 8) # int            \n",
    "            output_shp.field('rhu', 'F', 10, 8) # string, max-length\n",
    "            # access the CSV file\n",
    "            with codecs.open(output_csvdir+ os.sep + fnn + '.csv', 'rb', 'utf-8') as csvfile:\n",
    "                reader = csv.reader(csvfile, delimiter=',')\n",
    "            # skip the header\n",
    "                next(reader, None)\n",
    "                #loop through each of the rows and assign the attributes to variables\n",
    "                for row in reader:\n",
    "                    station = row[3]\n",
    "                    height= row[4]\n",
    "                    year = row[5]\n",
    "                    month = row[6]\n",
    "                    day = row[7]\n",
    "                    rhu= row[8]\n",
    "                    lng = float(row[1])\n",
    "                    lat = float(row[2])\n",
    "                    # create the point geometry\n",
    "                    output_shp.point(lng, lat)\n",
    "                    # add attribute data\n",
    "                    output_shp.record(station,lng, lat, height,year,month,day,rhu)  \n",
    "                    \n",
    "        if files[i].split('-')[1]=='PRE':\n",
    "            fnn = files[i].split('.')[0]\n",
    "#             print(fnn)\n",
    "            output_shp = shp.Writer(output_shpdir+ os.sep + \"%s.shp\" % fnn, shp.POINT, encoding='gbk') #encoding='utf-8'\n",
    "            # output_shp = shp.Writer(output+ os.sep + \"%s.shp\" % fnn.split('.')[0], shp.POINT) #encoding='utf-8'\n",
    "            # for every record there must be a corresponding geometry.\n",
    "            output_shp.autoBalance = 1\n",
    "            # create the field names and data type for each.you can omit fields here\n",
    "            output_shp.field('station', 'F', 10, 8) # float\n",
    "            output_shp.field('longitude', 'F', 10, 8) # float\n",
    "            output_shp.field('latitude', 'F', 10, 8) # float\n",
    "            output_shp.field('height', 'F', 10, 8) # float\n",
    "            output_shp.field('Year', 'F', 10, 8) # int\n",
    "            output_shp.field('Mon', 'F', 10, 8) # int\n",
    "            output_shp.field('Day', 'F', 10, 8) # int            \n",
    "            output_shp.field('dpre', 'F', 10, 8) # string, max-length\n",
    "            output_shp.field('npre', 'F', 10, 8) # string, max-length\n",
    "            output_shp.field('pre', 'F', 10, 8) # string, max-length\n",
    "            # access the CSV file\n",
    "            with codecs.open(output_csvdir+ os.sep + fnn + '.csv', 'rb', 'utf-8') as csvfile:\n",
    "                reader = csv.reader(csvfile, delimiter=',')\n",
    "            # skip the header\n",
    "                next(reader, None)\n",
    "                #loop through each of the rows and assign the attributes to variables\n",
    "                for row in reader:\n",
    "                    station = row[3]\n",
    "                    height= row[4]\n",
    "                    year = row[5]\n",
    "                    month = row[6]\n",
    "                    day = row[7]\n",
    "                    dpre= row[8]\n",
    "                    npre= row[9]\n",
    "                    pre= row[10]\n",
    "                    lng = float(row[1])\n",
    "                    lat = float(row[2])\n",
    "                    # create the point geometry\n",
    "                    output_shp.point(lng, lat)\n",
    "                    # add attribute data\n",
    "                    output_shp.record(station,lng, lat, height,year,month,day,dpre,npre,pre)  \n",
    "\n",
    "        if files[i].split('-')[1]=='SSD':\n",
    "            fnn = files[i].split('.')[0]\n",
    "#             print(fnn)\n",
    "            output_shp = shp.Writer(output_shpdir+ os.sep + \"%s.shp\" % fnn, shp.POINT, encoding='gbk') #encoding='utf-8'\n",
    "            # output_shp = shp.Writer(output+ os.sep + \"%s.shp\" % fnn.split('.')[0], shp.POINT) #encoding='utf-8'\n",
    "            # for every record there must be a corresponding geometry.\n",
    "            output_shp.autoBalance = 1\n",
    "            # create the field names and data type for each.you can omit fields here\n",
    "            output_shp.field('station', 'F', 10, 8) # float\n",
    "            output_shp.field('longitude', 'F', 10, 8) # float\n",
    "            output_shp.field('latitude', 'F', 10, 8) # float\n",
    "            output_shp.field('height', 'F', 10, 8) # float\n",
    "            output_shp.field('Year', 'F', 10, 8) # int\n",
    "            output_shp.field('Mon', 'F', 10, 8) # int\n",
    "            output_shp.field('Day', 'F', 10, 8) # int            \n",
    "            output_shp.field('ssd', 'F', 10, 8) # string, max-length\n",
    "            # access the CSV file\n",
    "            with codecs.open(output_csvdir+ os.sep + fnn + '.csv', 'rb', 'utf-8') as csvfile:\n",
    "                reader = csv.reader(csvfile, delimiter=',')\n",
    "            # skip the header\n",
    "                next(reader, None)\n",
    "                #loop through each of the rows and assign the attributes to variables\n",
    "                for row in reader:\n",
    "                    station = row[3]\n",
    "                    height= row[4]\n",
    "                    year = row[5]\n",
    "                    month = row[6]\n",
    "                    day = row[7]\n",
    "                    ssd= row[8]\n",
    "                    lng = float(row[1])\n",
    "                    lat = float(row[2])\n",
    "                    # create the point geometry\n",
    "                    output_shp.point(lng, lat)\n",
    "                    # add attribute data\n",
    "                    output_shp.record(station,lng, lat, height,year,month,day,ssd)  \n",
    "print('转矢量完成!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab8ef7",
   "metadata": {},
   "source": [
    "## 定义投影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03661b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T15:51:22.817329Z",
     "start_time": "2021-10-25T15:51:22.802309Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 定义投影\n",
    "# # jupyter notebook中无法写入，需要在pycharm中运行\n",
    "# proj = osr.SpatialReference() \n",
    "# proj.ImportFromEPSG(4326) # 4326-GCS_WGS_1984; 4490- GCS_China_Geodetic_Coordinate_System_2000\n",
    "# wkt = proj.ExportToWkt()\n",
    "# for root, dirs, files in os.walk(output_shpdir):\n",
    "#     print(root)\n",
    "# for i in range(len(files)):\n",
    "#     if files[i].split('.')[1] == 'shp':\n",
    "#         # 写入投影\n",
    "#         print(files[i])\n",
    "#         f = open((root+os.sep+files[i]).replace(\".shp\", \".prj\"), 'w') \n",
    "#         f.write(wkt)#写入投影信息\n",
    "#         f.close()#关闭操作流"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "408.097px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "790px",
    "left": "2011.43px",
    "right": "20px",
    "top": "145.988px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
